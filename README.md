# ğŸ›’ Store Daily Profit Reporting Pipeline (Airflow + MySQL + Docker)

## ğŸ“Œ Project Overview

This project implements a **production-grade ETL pipeline** using **Apache Airflow**, **MySQL**, and **Docker** to generate **daily store profit reports** from raw transaction data and automatically **email the reports**.

The pipeline:
- Validates raw data availability
- Cleans and transforms CSV data
- Loads data into MySQL
- Computes daily profits using SQL
- Generates CSV reports
- Emails the reports
- Archives raw input files

---

## ğŸ—ï¸ Architecture
```
Raw CSV
â†“
Airflow DAG
â†“
Python Data Cleaning
â†“
MySQL (Docker, Persistent Volume)
â†“
SQL Aggregations
â†“
CSV Reports
â†“
Email with Attachments

```
---

## ğŸ³ Tech Stack

- **Apache Airflow 2.x**
- **MySQL 8.0**
- **PostgreSQL** (Airflow metadata DB)
- **Docker & Docker Compose**
- **Python**
- **SQL**

---

## ğŸ“ Project Structure

```text
docker-airflow-master/
â”‚
â”œâ”€â”€> dags/
â”‚ â””â”€â”€> store_DAG.py
â”‚
â”œâ”€â”€> sql_files/
â”‚ â”œâ”€â”€> create_table.sql
â”‚ â”œâ”€â”€> insert_into_table.sql
â”‚ â””â”€â”€> select_from_table.sql
â”‚
â”œâ”€â”€> store_files/
â”‚ â”œâ”€â”€> raw_store_transactions.csv
â”‚ â””â”€â”€> (generated report files)
â”‚
â”œâ”€â”€> mysql.cnf
â”œâ”€â”€> docker-compose-LocalExecutor.yml
â””â”€â”€> README.md

```
---

## ğŸ”„ DAG Workflow

**DAG Name:** `store_dag`  
**Schedule:** `@daily`

### Task Flow

check_file_exists
â†“
clean_raw_csv
â†“
create_mysql_table
â†“
insert_into_table
â†“
cleanup_old_reports
â†“
select_from_table
â†“
move_file1 â”€â”
â”œâ”€â”€ send_email â†’ rename_raw
move_file2 â”€â”˜


### Task Description

| Task | Description |
|----|------------|
| `check_file_exists` | Verifies raw CSV exists |
| `clean_raw_csv` | Cleans and standardizes raw data |
| `create_mysql_table` | Creates MySQL table if not exists |
| `insert_into_table` | Loads cleaned CSV into MySQL |
| `cleanup_old_reports` | Deletes old CSV reports |
| `select_from_table` | Generates profit reports using SQL |
| `move_file1 / move_file2` | Renames reports with execution date |
| `send_email` | Emails reports as attachments |
| `rename_raw` | Archives raw input file |

---

## ğŸ§  Key Design Decisions

- **Airflow Macros (`{{ ds }}`, `{{ ds_nodash }}`)** used instead of `datetime.now()`
- **Idempotent pipeline** (safe to re-run)
- **Persistent MySQL storage** using Docker volumes
- **MySQL `INTO OUTFILE` limitation handled** via cleanup task
- **Airflow Connections UI** used for database credentials

---

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Start Services

```bash
cd docker-airflow-master
docker compose -f ./docker-compose-LocalExecutor.yml up -d
2ï¸âƒ£ Create Airflow Admin User
docker exec -it docker-airflow-master-webserver-1 bash
airflow users create \
  --username airflow \
  --password airflow \
  --firstname Airflow \
  --lastname Admin \
  --role Admin \
  --email admin@example.com
3ï¸âƒ£ Access Airflow UI
http://localhost:8080
Login:

username: airflow
password: airflow
ğŸ” Airflow Connection Setup
Create a MySQL connection in Admin â†’ Connections:

Field	Value
Connection Id	mysql_conn
Connection Type	MySQL
Host	mysql
Schema	airflow_mysql
Login	root
Password	root
Port	3306
ğŸ§ª Database Initialization (One-time)
docker exec -it docker-airflow-master-mysql-1 mysql -u root -proot
CREATE DATABASE airflow_mysql;
ğŸ“§ Email Reporting
Uses Airflow EmailOperator

Sends daily profit CSV reports as attachments

Fully automated post-success

âœ… Final Outcome
End-to-end ETL pipeline

Fully automated daily reporting

Restart-safe and production-ready

Clean DAG design following Airflow best practices

ğŸ¯ Key Learnings
Always use Airflow macros for dates

Persist databases using Docker volumes

MySQL SELECT INTO OUTFILE is write-once

Idempotency is critical in data pipelines

Airflow Connections override environment variables

ğŸš€ Future Improvements
Convert to TaskFlow API

Add data quality checks

Add SLA alerts

Move SQL OUTFILE logic to Python

Parameterize email recipients

ğŸ‘¤ Author
Navaneeth Rao T
Data Engineer
Apache Airflow | SQL | Docker | Python
